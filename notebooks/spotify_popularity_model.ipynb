{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Spotify Popularity Prediction\n",
        "\n",
        "This notebook builds a predictive model for Spotify track popularity (0-100) using audio and metadata features.\n",
        "\n",
        "It includes:\n",
        "- Data loading and cleaning\n",
        "- Exploratory data analysis (EDA)\n",
        "- Feature engineering (e.g., artist count, title signals)\n",
        "- Modeling (Linear Regression, Random Forest, optional XGBoost)\n",
        "- Evaluation (MAE, RMSE, RÂ²)\n",
        "- Visualizations (correlations, feature importances, SHAP, partial dependence)\n",
        "\n",
        "Set the `DATASET_PATH` below if your file is located elsewhere.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths\n",
        "from pathlib import Path\n",
        "DATASET_PATH = Path('/Users/anooptejthotapalli/Downloads/dataset-3-1.csv')\n",
        "assert DATASET_PATH.exists(), f\"Dataset not found at {DATASET_PATH}\"\n",
        "\n",
        "# Basics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Load\n",
        "df = pd.read_csv(DATASET_PATH)\n",
        "print(df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean column names: fix possible line-wrapped header cells\n",
        "# Sometimes CSVs from certain sources wrap header lines; we'll normalize columns.\n",
        "df.columns = [c.strip().replace('\\n', '').replace('  ', ' ') for c in df.columns]\n",
        "\n",
        "# Rename common wrapped columns if present\n",
        "rename_map = {\n",
        "    'danceabi lity': 'danceability',\n",
        "    'mod e': 'mode',\n",
        "    'time_signatur e': 'time_signature',\n",
        "}\n",
        "df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns}, inplace=True)\n",
        "\n",
        "# Drop unnamed index column if present\n",
        "for col in df.columns:\n",
        "    if col.lower().startswith('unnamed'):\n",
        "        df.drop(columns=[col], inplace=True)\n",
        "        break\n",
        "\n",
        "print('Columns:', list(df.columns))\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic EDA\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "non_target_numeric = [c for c in numeric_cols if c != 'popularity']\n",
        "\n",
        "print(df[numeric_cols].describe().T)\n",
        "\n",
        "# Correlation heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(df[numeric_cols].corr(), cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Heatmap (Numeric Features)')\n",
        "plt.show()\n",
        "\n",
        "# Popularity distribution\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.histplot(df['popularity'], bins=30, kde=True)\n",
        "plt.title('Popularity Distribution')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature engineering\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Derived features\n",
        "if 'artists' in df.columns:\n",
        "    df['num_artists'] = df['artists'].astype(str).str.split(';').apply(len)\n",
        "else:\n",
        "    df['num_artists'] = 1\n",
        "\n",
        "if 'track_name' in df.columns:\n",
        "    lower_titles = df['track_name'].astype(str).str.lower()\n",
        "    df['title_len'] = lower_titles.str.len()\n",
        "    df['title_has_feat'] = lower_titles.str.contains('feat|ft\\.|with', regex=True).astype(int)\n",
        "else:\n",
        "    df['title_len'] = 0\n",
        "    df['title_has_feat'] = 0\n",
        "\n",
        "categorical_cols = []\n",
        "if 'track_genre' in df.columns:\n",
        "    categorical_cols.append('track_genre')\n",
        "\n",
        "# One-hot encode single categorical (keep low cardinality)\n",
        "if categorical_cols:\n",
        "    enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "    ohe = enc.fit_transform(df[categorical_cols])\n",
        "    ohe_cols = [f\"{categorical_cols[0]}__{cat}\" for cat in enc.categories_[0]]\n",
        "    ohe_df = pd.DataFrame(ohe, columns=ohe_cols, index=df.index)\n",
        "    df = pd.concat([df.drop(columns=categorical_cols), ohe_df], axis=1)\n",
        "\n",
        "features = [c for c in df.columns if c not in ['popularity','track_id','artists','album_name','track_name']]\n",
        "X = df[features]\n",
        "y = df['popularity']\n",
        "X.shape, y.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "X_train.shape, X_test.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline and tree-based models\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "models = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    'RandomForest': RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    results[name] = {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
        "    print(f\"{name}: MAE={mae:.3f} RMSE={rmse:.3f} R2={r2:.3f}\")\n",
        "\n",
        "best_model_name = max(results, key=lambda k: results[k]['R2'])\n",
        "best_model = models[best_model_name]\n",
        "print('Best model:', best_model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance (for tree models)\n",
        "importances = None\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    importances = pd.Series(best_model.feature_importances_, index=X_train.columns)\n",
        "    top20 = importances.sort_values(ascending=False).head(20)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.barplot(x=top20.values, y=top20.index)\n",
        "    plt.title(f'Top 20 Feature Importances ({best_model_name})')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print('Best model has no feature_importances_ attribute.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SHAP explanations (optional; can be heavy on very large datasets)\n",
        "!pip -q install shap >/dev/null\n",
        "import shap\n",
        "\n",
        "# Use a sample for speed\n",
        "sample_idx = np.random.RandomState(42).choice(X_test.index, size=min(2000, len(X_test)), replace=False)\n",
        "X_sample = X_test.loc[sample_idx]\n",
        "\n",
        "explainer = None\n",
        "if best_model_name == 'RandomForest':\n",
        "    explainer = shap.TreeExplainer(best_model)\n",
        "    shap_values = explainer.shap_values(X_sample)\n",
        "    shap.summary_plot(shap_values, X_sample, show=False)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    # KernelExplainer fallback\n",
        "    explainer = shap.KernelExplainer(best_model.predict, shap.sample(X_train, 200))\n",
        "    shap_values = explainer.shap_values(X_sample)\n",
        "    shap.summary_plot(shap_values, X_sample, show=False)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation visualizations\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "preds = best_model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, preds)\n",
        "rmse = mean_squared_error(y_test, preds, squared=False)\n",
        "r2 = r2_score(y_test, preds)\n",
        "print(f\"Final ({best_model_name}) -> MAE={mae:.3f} RMSE={rmse:.3f} R2={r2:.3f}\")\n",
        "\n",
        "# Prediction vs Actual\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test, preds, alpha=0.3)\n",
        "lims = [min(y_test.min(), preds.min()), max(y_test.max(), preds.max())]\n",
        "plt.plot(lims, lims, 'r--')\n",
        "plt.xlabel('Actual Popularity')\n",
        "plt.ylabel('Predicted Popularity')\n",
        "plt.title('Prediction vs Actual')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Residuals\n",
        "residuals = y_test - preds\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.histplot(residuals, bins=30, kde=True)\n",
        "plt.title('Residuals Distribution')\n",
        "plt.xlabel('Residual (Actual - Predicted)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Partial Dependence (selected features)\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "\n",
        "selected_features = [f for f in ['danceability','energy','acousticness','valence','tempo'] if f in X_train.columns]\n",
        "if selected_features:\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    PartialDependenceDisplay.from_estimator(best_model, X_train, selected_features, ax=ax)\n",
        "    plt.suptitle('Partial Dependence Plots')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print('Selected features not found for PDP.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model\n",
        "import joblib\n",
        "MODEL_PATH = Path('../models/best_spotify_popularity_model.pkl')\n",
        "joblib.dump(best_model, MODEL_PATH)\n",
        "print('Saved model to', MODEL_PATH.resolve())\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
